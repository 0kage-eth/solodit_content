**Auditors**

[Zokyo](https://x.com/zokyo_io)

# Findings

## High Risk

### Missed validation of potentially corrupted oracle.
**Description**

Aggregator Oracle.sol: aggregate Underlying(), line 413 (Note comment)
The note says about the issue which may occur in case of insanely high price. In such a case the division result of oQuote TokenLiquidity / oPrice will equal 0. Thus, the oracle response will be marked as valid, but the resulting price will have lower denominator and will be corrupted. Such an issue can not occur in normal obstacles, but it can occur in case of corrupted oracle which returns harmful data. Since the contract itself has not cross-validation between the oracles, and the only sanity checks performed in validateUnderlying Consultation() are based on the data from the Oracle itself, such an issue may occur. And in such case data can be manipulated from the outer source (which have no verification procedure) to pass the sanityCheckTvlDistributionRatio() check and still have the mentioned impact. Issue is marked as high, due the high impact on the logic and actually high risk of happening. Although the question of cross-validation of oracles is out of the scope of the audit due the nature of oracles, the potential data corruption by some of the oracles is a serious issue since it directly influences the logic of current contracts set.

**Recommendation**

Verify the correct validation of the number of required valid answers from the aggregated oracles.

**Re-audit comment**

Verified.

Post-audit:
after the consultation with the Adrastia team it was verified, that the logic of division is correct, since oQuote TokenLiquidity is shifted to the left by 120 bits before it's used. Therefore, as long as oQuote TokenLiquidity is not equal to 0, it will be larger than oPrice since prices are stored in 112-bit numbers. So, it is impossible for the division result of oQuote TokenLiquidity / oPrice to equal 0.

## Medium Risk

### Curve pool interface should be verified.
**Description**

Curve PriceAccumulator.sol

Currently, the curve price accumulator is using the interface of the curve pool with the function get_dy() with the following parameters (int128 i, int128 j, uint256 dx). However there is another version of this function in the Curve protocol with parameters (uint256 i, uint256j, uint256 dx). For example, such an interface is utilized by TriCryptoPool. Due to interface mismatch, some curve pools can't be supported.

**Recommendation**

Add a support of another get_dy() interface or verify the correctness of the implementation.

**Re-audit comment**

Resolved

## Low Risk

### Parameters lack validation.
**Description**

LiquidityAccumulator.sol, PriceAccumulator.sol: cunstructor.

Parameters minUpdateDelay_ and maxUpdateDelay_should be validated, so that maxUpdate Delay_ is greater than minUpdateDelay_.

**Recommendation**

Validate parameters in constructor.

**Re-audit comment**

Resolved

## Informational

### Repeatable calculations in update function.
**Description**

LiquidityAccumulator.sol, PriceAccumulator.sol: update().

Function calls fetchLiqudity() or fetchPrice() two times, increasing gas spendings for function update(). First time it is called during checking that the token needs an update (In function change ThresholdSurpassed (address token, uint256 change Threshold)). Then it is called in the function performUpdate().

**Recommendation**

Consider returning the values of liquidities and price after first calculation and reuse it in the function performUpdate().

**Re-audit comment**

Unresolved

### Unhandled period value in calculateMaxAge.
**Description**

AggregatorOracle.sol: calculateMaxAge().

Since period for the PeriodicOracle can be set to 0, this function has unhandled case which can influence the contracts correct usage by the dApp.

**Recommendation**

Add handling of zero period case.

**Re-audit comment**

Resolved.

From client:

The setting of a period of 0 seconds was disallowed, since calculating data over a period of 0 seconds doesn't make sense. Also the issue is fixed where AggregatedOracle#calculateMaxAge returns 0 because as outlined in the interface documentation, a max-age of 0 gets the instant rates as of the latest block, which is not what's expected of the aggregated oracle.

### Minimal number of responses for oracle aggregation.
**Description**

Aggregator Oracle.sol: canUpdate(), performUpdate().

Both functions for the update check and update performance use the same minimal number of valid oracles updates: validResponses $>=1$, requesting minimum 1 correct response. Since the oracle aggregates data from several sources and the aggregation itself is a powerful tool against the incorrect data consuming, it is important to carefully evaluate the results gathered from those sources. Thus, more sources have delivered correct data - more trust the aggregator has. Thus, the validation upon at least 1 source seems not enough for the complex oracles system. Issue is marked as info, since it requires business logic verification from the team, thus may not be classified as security issues.

**Recommendation**

Verify the correct validation of the number of required valid answers from the aggregated oracles.

**Re-audit comment**

Resolved.

From client:

Added support for the minimum number of underlying oracle consultations to be changed from the default. By the Customer's experience with using oracles built around Uniswap and Curve, as long as one DEX has enough liquidity to make performing arbitrage profitable (assuming the presence of arbitrageurs), only 1 response is needed. The sanity checks for minimum quote token liquidity and minimum token liquidity value of each underlying oracle can be used to ensure this. With that being said, the more liquidity backing up the price, the more reliable and accurate the price is and the more costly it is to attack. Oracle consumers can use the consult function to retrieve price and liquidities, then they can alternate to a fallback oracle if there's not enough liquidity backing up the price.

### Potential violated oracle handling procedure.
**Description**

Aggregator Oracle.sol: canUpdate(), performUpdate().

There is pretty high risk of the violation of one or several of aggregated Oracles (due to the hack of that oracle, or mistake in calculations, or pool draining, or corrupted data writing), thus there can be not full confidence in all of aggregated sources. Such oracles nature puts a question of the reliability of the AggregatorOracle in case if one or several of aggregated sources are violated. And for such case the protocol has no procedure of the oracle "de-violation": no pause, no corrupted oracle deletion, no reverts, no zero-data return instead of price (e.g. return of Os in case of oracles violated). Thus, even if the oracle will be immediately re-deployed, it still leaves the place for corrupted data usage that may lead to exploits of "oracle manipulation" type. So, the protocol needs the procedure of (first of all) violated sources detection, and prevention of their influence on the final price. Issue is marked as info, since it requires business logic verification from the team, thus may not be classified as security issues. Though in this case the issue may lead to critical results in case of ignoring violated sources and using the average price over corrupted data. negative threshold is equal to 100%; positive threshold is equal to 10000%.

**Recommendation**

Verify the correctness of the sources, or bring the procedure of the violation detection and removal/deactivation OR bring the procedure of the whole oracle deactivation.

**Re-audit comment**

Verified.

From client:

The functionality is confirmed to correspond the design. It is the responsibility of the oracle consumer to validate that the aggregated oracle and all of the underlying oracles are set up correctly and in alignment with their requirements and assumptions. The system has been designed to be immutable so as to guarantee that corrupted or corruptible underlying oracles are not maliciously introduced while the aggregated oracle is in use. Also, it is confirmed by the Adrastia team, that there are plans to establish a DAO later down the road with the ability to swap the underlying oracles and/or pause the oracles, but only when the protocol is sufficiently decentralized.

From client:

Requiring minimum token liquidity value and also minimum quote token liquidity handles cases where the underlying pools are drained. In such cases where this validation fails, the underlying oracle will be ignored. There are some other attack vectors involving Uniswap V3 where there's one-sided liquidity or where there are large gaps between ticks causing the price to not get updated. If the aforementioned validation doesn't catch this, the TVL distribution ratio validation typically will, but not always. Therefore, extra caution must be taken when including or using the Uniswap V3 oracle. If all underlying oracles fail such validations, or if the underlying oracles aren't up-to-date, the aggregated oracle will not update. It's recommended for oracle consumers to use consult(token, maxAge) where the maxAge is the required freshness of the data, in seconds. In the case where the oracle hasn't been updated in the last maxAge seconds, the function will revert. Consumers can then catch the exception and fall back on an alternative oracle.

### Observation update interpretation.
**Description**

PeriodicAccumulation Oracle.sol: performUpdate().

updated Observation variable can be set to true only with the price updated, but without liquidity updated. The logic allows to have only price updated within the observation (line 101 - setting of the variable after the successful price update) but still emit event about the update (line 155 - the condition accepts set updatedObservation value and default missing Price setting to false). Verify, that there is no need for a liquidity update for such logic (since in case if liquidity is not updated from the LiquidityAccumulator - there is no influence on the event emitting). Issue is marked as info, since it requires business logic verification from the team, thus may not be classified as security issues.

**Recommendation**

Verify the correctness of the observation update interpretation.

**Re-audit comment**

Verified.

From client:

It's okay for liquidities to be reported as 0 in the case where the oracle doesn't have enough information to calculate liquidity. Liquidities are used in the aggregated oracle, and in the case that the oracle reports 0 liquidity, it'll be ignored by the aggregator (note: this is confirmed by the auditors team). The price is the important component, so in the case where the oracle doesn't have enough information to calculate the price, it doesn't update the timestamp. This will cause consultation to revert, with the message 'MISSING_OBSERVATION'. This will also make it so that no 'Updated' events are emitted. All-in-all, the end result in this case will seemingly be that no observation is made.

### Assumption for updated accumulators.
**Description**

PeriodicAccumulation Oracle.sol: performUpdate(), line 84.

The note states, that for the gas optimizations the logic assumes, that accumulators are up-to-date. Auditors need verification from the Adrastia team according the reasons behind the assumption. Issue is marked as info, since it requires business logic verification from the team, thus may not be classified as security issues. Issue will not be displayed in the report, but will be described in the executive summary and the protocol overview sections, since it relates to the core interaction between the contracts.

**Recommendation**

Verify the assumption that accumulators are up-to-date or implement checks.

**Re-audit comment**

Resolved.

Post-audit:

Adrastia team has confirmed the issue and added validation to the PeriodicAccumulation Oracle with checks for accumulators to be updated.
